{"cells":[{"cell_type":"markdown","id":"d8468209","metadata":{"id":"d8468209"},"source":["### _해당 파일은 텍스트분석을 도와주는 함수들을 정리한 파일이다_"]},{"cell_type":"markdown","id":"bb23c635","metadata":{"id":"bb23c635"},"source":["## 기본 패키지들"]},{"cell_type":"code","source":["#코랩에서 konlpy 설치하는 방법\n","!apt-get update\n","!apt-get install g++ openjdk-8-jdk \n","!pip3 install konlpy JPype1-py3\n","!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"],"metadata":{"id":"OJQUuDpfOR-Y"},"id":"OJQUuDpfOR-Y","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"4725a992","metadata":{"scrolled":true,"id":"4725a992","outputId":"675ce4f5-0698-4391-a0d2-cb3e4956e354"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\wips\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\wips\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\wips\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\wips\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\wips\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["#base\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","#정규표현식\n","import re\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","#불용어\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize \n","from nltk.stem import WordNetLemmatizer\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('averaged_perceptron_tagger')\n","\n","#토큰화\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import WordPunctTokenizer\n","from nltk.tokenize import TreebankWordTokenizer\n","\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","\n","#워드클라우드\n","from wordcloud import WordCloud\n","from konlpy.tag import Twitter\n","from collections import Counter"]},{"cell_type":"code","execution_count":null,"id":"15e0373a","metadata":{"scrolled":true,"id":"15e0373a","outputId":"f88e88e9-23a1-4168-ab4a-e3531d9ea55d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>num</th>\n","      <th>data</th>\n","      <th>ryu</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2021.09.09</td>\n","      <td>09, 41, 42, 45</td>\n","      <td>Application programming interface (API) for co...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2021.09.09</td>\n","      <td>09, 38, 41, 42</td>\n","      <td>Computer hardware; software development tools;...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>2020.06.18</td>\n","      <td>9</td>\n","      <td>Computer hardware and downloadable software fo...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>2020.06.12</td>\n","      <td>09, 35, 41, 42, 45</td>\n","      <td>Downloadable application programming interface...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>2020.06.11</td>\n","      <td>09, 35, 41, 42, 45</td>\n","      <td>Application programming interface (API) for co...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   num        data                 ryu  \\\n","0    1  2021.09.09      09, 41, 42, 45   \n","1    2  2021.09.09      09, 38, 41, 42   \n","2    3  2020.06.18                   9   \n","3    4  2020.06.12  09, 35, 41, 42, 45   \n","4    5  2020.06.11  09, 35, 41, 42, 45   \n","\n","                                                text  \n","0  Application programming interface (API) for co...  \n","1  Computer hardware; software development tools;...  \n","2  Computer hardware and downloadable software fo...  \n","3  Downloadable application programming interface...  \n","4  Application programming interface (API) for co...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["path = 'C:/Users/wips/Desktop/업무폴더/1주차업무/'\n","data =pd.read_csv(path+'facebook.csv')\n","data.head()"]},{"cell_type":"markdown","id":"07cb8443","metadata":{"id":"07cb8443"},"source":["## 전처리 함수"]},{"cell_type":"markdown","id":"aacde07e","metadata":{"id":"aacde07e"},"source":["### punctuations"]},{"cell_type":"code","execution_count":null,"id":"b76deb1b","metadata":{"id":"b76deb1b"},"outputs":[],"source":["# 다른 문자들의 존재 여부 확인 [^안에 든 문자들 뺀]\n","def show_not_alphanum(text):\n","    return re.findall(\"[^0-9a-zA-Z‘’\\'\\- \\,\\. ]\",text)"]},{"cell_type":"code","execution_count":null,"id":"d03595c3","metadata":{"id":"d03595c3"},"outputs":[],"source":["# 주의할 연결 문자   \n","text.apply(lambda x : re.findall(\"\\w{1,}\\_\\w{1,}\",x)) # 언더바(_)\n","text.apply(lambda x : re.findall(\"\\w{1,}\\-\\w{1,}\",x)) # 하이픈(-)\n","text.apply(lambda x : re.findall(\"\\w{1,}\\'\\w{1,}\",x)) # appostrophe(') \n","text.apply(lambda x : re.findall(\"\\w{1,}\\.\\w{1,}\",x)) # 간혹 마침표"]},{"cell_type":"code","execution_count":null,"id":"efe5b5f5","metadata":{"id":"efe5b5f5"},"outputs":[],"source":["# 다른 문자들은 모두 없애줘\n","def only_alphanum(text):\n","    return re.sub(\"[^0-9a-zA-Z\\- ]\",'',text)"]},{"cell_type":"markdown","id":"1aa9c2dc","metadata":{"id":"1aa9c2dc"},"source":["### tokenization"]},{"cell_type":"code","execution_count":null,"id":"cebe28aa","metadata":{"id":"cebe28aa"},"outputs":[],"source":["WordPunctTokenizer().tokenize(text)\n","TreebankWordTokenizer().tokenize(text)"]},{"cell_type":"markdown","id":"d4311cbd","metadata":{"id":"d4311cbd"},"source":["### capitals"]},{"cell_type":"code","execution_count":null,"id":"9ac8e5b6","metadata":{"id":"9ac8e5b6"},"outputs":[],"source":["#대문자 확인\n","def check_caps(all_list):\n","    empty = []\n","    for i in all_list:\n","        if i.isupper() == True:\n","            empty.append(i)\n","    return empty"]},{"cell_type":"code","execution_count":null,"id":"a6de5914","metadata":{"id":"a6de5914"},"outputs":[],"source":["# 문제 없는 애들은 모두 소문자로 변경\n","data = [i for i in data if i not in set(capitals)]\n","data = [x.lower() for x in data]"]},{"cell_type":"markdown","id":"2af7be95","metadata":{"id":"2af7be95"},"source":["### short words"]},{"cell_type":"code","execution_count":null,"id":"80f7e417","metadata":{"id":"80f7e417"},"outputs":[],"source":["data = [i for i in data if len(i)>1]"]},{"cell_type":"markdown","id":"7b9338a7","metadata":{"id":"7b9338a7"},"source":["### stopwords"]},{"cell_type":"code","execution_count":null,"id":"f8b7576d","metadata":{"id":"f8b7576d"},"outputs":[],"source":["stop_words_list = stopwords.words('english');len(stop_words_list)\n","tok_2021 = [i for i in tok_2021 if i not in stop_words_list]"]},{"cell_type":"markdown","id":"028e5d86","metadata":{"id":"028e5d86"},"source":["### Lenmmatization"]},{"cell_type":"code","execution_count":null,"id":"c39381e0","metadata":{"id":"c39381e0"},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()\n","lemma_toks = [lemmatizer.lemmatize(x) for x in tok_2021]\n","print(len(set(tok_2021)),len(set(lemma_toks))) #단어가 줄긴했음"]},{"cell_type":"markdown","id":"a1a87728","metadata":{"id":"a1a87728"},"source":["### 특정 품사만 추출"]},{"cell_type":"code","execution_count":null,"id":"9dc4ebec","metadata":{"id":"9dc4ebec"},"outputs":[],"source":["adj_list=[]\n","for j in docs:\n","  bin_list2=[]\n","  for word in nltk.tag.pos_tag(j):\n","    if word[1] in [ 'JJ', 'JJR', 'JJS']: #형용사\n","      bin_list2.append(word[0])\n","#    bin_list2 = [i for i in bin_list2 if i not in ['']] \n","  adj_list.append(bin_list2)\n","len(adj_list)"]},{"cell_type":"markdown","id":"cc50c759","metadata":{"id":"cc50c759"},"source":["### auto-process"]},{"cell_type":"code","execution_count":null,"id":"408d597c","metadata":{"id":"408d597c"},"outputs":[],"source":["#데이터프레임 내 텍스트를 토큰화하는 함수\n","\n","def all_process(datas):\n","    \n","    datas.text = datas.text.apply(only_alphanum)\n","    tokens = datas.text.apply(lambda x : tokenizer.tokenize(x))\n","    tok=[]\n","    \n","    for i in tokens.index:\n","      tok.extend(tokens[i])\n","\n","    capitals = list(check_caps(tok))\n","    tok = [i for i in tok if i not in set(capitals)]\n","    tok = [x.lower() for x in tok]\n","    tok.extend(capitals)\n","\n","    tok = [i for i in tok if len(i)>1]\n","    tok = [i for i in tok if i not in stop_words_list]\n","\n","    lemmatizer = WordNetLemmatizer()\n","    lemma_toks = [lemmatizer.lemmatize(x) for x in tok]\n","\n","    return lemma_toks"]},{"cell_type":"markdown","id":"fcbd0e9f","metadata":{"id":"fcbd0e9f"},"source":["### technics"]},{"cell_type":"code","execution_count":null,"id":"29dc4f83","metadata":{"id":"29dc4f83"},"outputs":[],"source":["# make yearly data\n","\n","years =list(data.date.str[:4].unique()) #2005년부터 2021년까지\n","#years.sort(reverse=True)\n","\n","data_list =['data_' + i for i in years] #데이터 명 생성\n","\n","#연도 별 dataframe\n","for i,j in enumerate(years):\n","  locals()[data_list[i]] = data.loc[data['date'].apply(lambda x : x.startswith(j)),]"]},{"cell_type":"code","execution_count":null,"id":"11c84079","metadata":{"id":"11c84079"},"outputs":[],"source":["# 모든 문서에서 자주나오는 단어는 문서 구분에서는 필요 없다.\n","# 이를 다시 반영하여 함수 생성\n","def all_process2(datas):\n","    datas.text = datas.text.apply(only_alphanum)\n","\n","    tokens = datas.text.apply(lambda x : tokenizer.tokenize(x))\n","    tok=[]\n","    for i in tokens.index:\n","      tok.extend(tokens[i])\n","\n","    capitals = list(check_caps(tok))\n","    tok = [i for i in tok if i not in set(capitals)]\n","    tok = [x.lower() for x in tok]\n","    tok.extend(capitals)\n","\n","    tok = [i for i in tok if len(i)>1]\n","    tok = [i for i in tok if i not in stop_words_list]\n","\n","    lemmatizer = WordNetLemmatizer()\n","    lemma_toks = [lemmatizer.lemmatize(x) for x in tok]\n","\n","    lemma_toks = [i for i in lemma_toks if i not in most_frequency_words]\n","\n","    return lemma_toks\n","\n","\n","for i,j in enumerate(token_list):\n","  locals()[j] = all_process2(data.loc[data['date'].apply(lambda x : x.startswith(years[i])),])"]},{"cell_type":"markdown","id":"cc69c2ff","metadata":{"id":"cc69c2ff"},"source":["### DTM"]},{"cell_type":"code","execution_count":null,"id":"dabda0f3","metadata":{"id":"dabda0f3"},"outputs":[],"source":["from math import log\n","\n","def tf(t, d):\n","  return d.count(t)\n","\n","def idf(t):\n","  df = 0\n","  for doc in docs:\n","    df += t in doc\n","  return log(N/(df+1))\n","\n","def tfidf(t, d):\n","  return tf(t,d)* idf(t)"]},{"cell_type":"markdown","id":"327b15c3","metadata":{"id":"327b15c3"},"source":["### TF-IDF"]},{"cell_type":"code","execution_count":null,"id":"e6d74b65","metadata":{"id":"e6d74b65"},"outputs":[],"source":["#N = 총 문서의 수\n","#docs = [문서들]\n","#vocab = list(words)\n","\n","def tf_idf_frame(N,docs,vocab):\n","    result = []\n","    for i in range(N):\n","      result.append([])\n","      d = docs[i]\n","      for j in range(len(vocab)):\n","        t = vocab[j]\n","        result[-1].append(tfidf(t,d))\n","\n","    tfidf_ = pd.DataFrame(result, columns = vocab)\n","    return(tfidf_)"]},{"cell_type":"markdown","id":"5e807d26","metadata":{"id":"5e807d26"},"source":["## 시각화"]},{"cell_type":"markdown","id":"405b3028","metadata":{"id":"405b3028"},"source":["### 워드클라우드"]},{"cell_type":"code","execution_count":null,"id":"4b54be9f","metadata":{"id":"4b54be9f"},"outputs":[],"source":["def cloud_making(data):\n","    wc = WordCloud(background_color=\"white\", max_font_size=60)\n","    cloud = wc.generate_from_frequencies(dict(data))\n","    \n","    plt.figure(figsize=(10, 8))\n","    plt.axis('off')\n","    plt.imshow(cloud)\n","    plt.show()"]},{"cell_type":"markdown","id":"80dd82f2","metadata":{"id":"80dd82f2"},"source":["### 예쁜 그래프 그리기"]},{"cell_type":"code","execution_count":null,"id":"bfec7994","metadata":{"id":"bfec7994"},"outputs":[],"source":["def main():\n","\t#### 1. bar plot으로 나타낼 데이터 입력\n","\tmodels = ['unique_words']\n","\tyticks = list(cnt_all_df.index)\n","\tdata = {'unique_words' :list(cnt_all_df.unique_words)}\n","\t\n","\t#### 2. matplotlib의 figure 및 axis 설정\n","\tfig, ax = plt.subplots(1,1,figsize=(7,10)) # 1x1 figure matrix 생성, 가로(14인치)x세로(10인치) 크기지정\n","\theight = 0.15\n","\t#ax.axvline(200, c='r', ls='--') 내가 원하는 틱에 빨간선 긋는 코드\n","\t#### 3. bar 그리기\n","\tfor i, model in enumerate(models):\n","\t\tpos = compute_pos(yticks, height, i, models)\n","\t\tbar = ax.barh(pos, data[model], height=height*0.95, label=model)\n","\t\tpresent_width(ax, bar) # bar너비 출력\n","\t\n","\t#### 4. x축 세부설정\n","\tax.set_xlim([내가원하는범위]) \n","\tax.set_xticks([내가원하는틱])\n","\tax.xaxis.set_tick_params(labelsize=10)\n","\tax.set_xlabel('x-name', fontsize=14)\n","\t\n","\t#### 5. y축 세부설정\n","\tax.set_yticks(range(len(yticks)))\n","\tax.set_yticklabels(yticks, fontsize=10)\t\n","\tax.set_ylabel('y-name', fontsize=10)\n","\t\n","\t#### 6. 범례 나타내기\n","\tbox = ax.get_position() # 범례를 그래프상자 밖에 그리기위해 상자크기를 조절\n","\tax.set_position([box.x0, box.y0, box.width * 0.9, box.height])\n","\tax.legend(loc='upper right',  shadow=True, ncol=1)\n","\t\n","\t#### 7. 보조선(눈금선) 나타내기\n","\tax.set_axisbelow(True)\n","\tax.xaxis.grid(True, color='gray', linestyle='dashed', linewidth=0.5)\n","\t\n","\t#### 8. 그래프 저장하고 출력하기\n","\t#plt.savefig('ex_barhplot.png', format='png', dpi=300)\n","\n","\tplt.show()\n","\t\n","def compute_pos(yticks, height, i, models):\n","  index = np.arange(len(yticks))\n","  n = len(models)\n","  correction = i - 0.5*(n-1)\n","  return index + height * correction\n","\n","def present_width(ax, bar):\n","\tfor rect in bar:\n","\t\twitdh = rect.get_width()\n","\t\tposx = witdh*1.01\n","\t\tposy = rect.get_y()+rect.get_height()*0.5\n","\t\tax.text(posx, posy, witdh, rotation=0, ha='left', va='center')\n","\n","# 이거 코드 돌리면 바로 실행됨!        \n","if __name__=='__main__':\n","\tmain()\n"," \n"]},{"cell_type":"markdown","id":"4a46bf1c","metadata":{"id":"4a46bf1c"},"source":["### 데이터프레임 기반 깔끔한 그래프"]},{"cell_type":"code","execution_count":null,"id":"c289c01d","metadata":{"id":"c289c01d"},"outputs":[],"source":["#bar\n","def bar_graph():\n","    fig2, ax2 = plt.subplots()\n","    df.plot.bar(x='index',alpha=0.5,figsize=(10,10),ax=ax2)\n","    plt.xticks(rotation=0,fontsize=13)\n","    plt.title('VR vs SNS by rate(%)',fontsize=15)\n","    plt.xlabel([],fontsize=0)\n","    # ax2.set_yticklabels([]) 틱 없애줌\n","    plt.tick_params(axis='both',which='both',left=False)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"6eb2e8bc","metadata":{"id":"6eb2e8bc"},"outputs":[],"source":["#line\n","def line_graph():\n","    fig2, ax2 = plt.subplots()\n","    vr_sns_df.VR.plot(x=vr_sns_df['index'],alpha=0.3,figsize=(10,5),ax=ax2, linewidth=3)\n","    vr_sns_df.SNS.plot(x=vr_sns_df['index'],alpha=0.3,figsize=(10,5),ax=ax2, linewidth=3)\n","    ax2.set_yticklabels([])\n","    ax2.set_xticklabels(['0']+list(vr_sns_df['index']))\n","    plt.tick_params(axis='both',which='both',left=False)\n","    title = 'VR vs SNS by rate(%)'\n","    ax2.set_title(title,fontsize=15)\n","    ax2.legend(prop={'size':10},loc=2)\n","    plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}